{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# Chains in LangChain\n",
    "- Chains are invaluable due to their capacity to effortlessly blend diverse components, shaping a singular and coherent application. \n",
    "- Through the creation of chains, multiple elements can seamlessly come together.\n",
    "-  A chain is crafted to take in user input, polish it using a PromptTemplate, and subsequently pass on this refined response to a large language model (LLM).\n",
    "\n",
    "## Outline\n",
    "\n",
    "* LLMChain\n",
    "* Sequential Chains\n",
    "  * SimpleSequentialChain\n",
    "  * SequentialChain\n",
    "* Router Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edc6b36",
   "metadata": {},
   "source": [
    "## Importing Libraries and Basic worflow setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39eba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "#!pip install --upgrade langchain\n",
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3699924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541eb2f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3b61a3-92eb-4891-90ee-1d10607b05ad",
   "metadata": {},
   "source": [
    "Note: LLM's do not always produce the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4336d784-65c2-4a11-8489-b445b1fad177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7a09c35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GlamourGlow Lipstick</td>\n",
       "      <td>GlamourGlow lipstick is fantastic! The color i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RubyRose Lipstick</td>\n",
       "      <td>I was disappointed with RubyRose lipstick. The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SilkShimmer Lipstick</td>\n",
       "      <td>SilkShimmer lipstick exceeded my expectations!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CrimsonCharm Lipstick</td>\n",
       "      <td>CrimsonCharm lipstick is a miss for me. The co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VelvetVogue Lipstick</td>\n",
       "      <td>VelvetVogue lipstick is amazing! It glides on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Product                                             Review\n",
       "0   GlamourGlow Lipstick  GlamourGlow lipstick is fantastic! The color i...\n",
       "1      RubyRose Lipstick  I was disappointed with RubyRose lipstick. The...\n",
       "2   SilkShimmer Lipstick  SilkShimmer lipstick exceeded my expectations!...\n",
       "3  CrimsonCharm Lipstick  CrimsonCharm lipstick is a miss for me. The co...\n",
       "4   VelvetVogue Lipstick  VelvetVogue lipstick is amazing! It glides on ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940ce7c",
   "metadata": {},
   "source": [
    "## LLMChain\n",
    "- The LLMChain represents the most basic form of chain within this system.\n",
    "- Within this setup, the LLMChain accepts various input parameters.\n",
    "    - It employs the PromptTemplate to transform these inputs into a coherent prompt. \n",
    "    - This polished prompt is then inputted into the model. \n",
    "    - After receiving the output, the LLMChain uses the OutputParser, if provided, to further refine and format the result into its ultimate usable form.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943237a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcdb42d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"How can you describe this {product} in a single word?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7abc20b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad44d1fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "product = \"CrimsonCharm Lipstick\"\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65329bed",
   "metadata": {},
   "source": [
    "*Output would look like this:<br>*\n",
    "\n",
    "**> Entering new LLMChain chain...<br>**\n",
    "Prompt after formatting:<br>\n",
    "<span style=\"color:green\">Human: How can you describe this CrimsonCharm Lipstick in a single word?</span>\n",
    "\n",
    "**> Finished chain.<br>**\n",
    "\n",
    "'Bold.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b03469",
   "metadata": {},
   "source": [
    "## SequentialChain\n",
    "- A sequential chain is a chain that combines various individual chains, where the output of one chain serves as the input for the next in a continuous sequence. \n",
    "- It operates by running a series of chains consecutively.\n",
    "\n",
    "## SimpleSequentialChain\n",
    "- Sequential chains, in their simplest form, consist of steps where each step takes one input and produces one output. \n",
    "- The output from one step becomes the input for the next.\n",
    "- This sequential approach ensures systematic and efficient handling of data, making it ideal for scenarios where a linear flow of information processing is essential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f31aa8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5d5b76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1eb2c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78458efe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8b5d44",
   "metadata": {},
   "source": [
    "*Output would look like this:*\n",
    "\n",
    "**> Entering new SimpleSequentialChain chain...</br>**\n",
    "<span style=\"color:crimson\">CrimsonCharm Cosmetics.</span></br>\n",
    "<span style=\"color:blue\">CrimsonCharm Cosmetics is a luxury makeup brand that offers a range of high-quality beauty products, including lipstick, eyeshadow, and foundation. The brand is known for its rich, bold colors and impeccable formulations, which are designed to enhance and beautify any complexion. With a commitment to using only the finest ingredients and state-of-the-art manufacturing techniques, CrimsonCharm Cosmetics has gained a loyal following among beauty enthusiasts and professionals alike. Whether you're looking for a bold, dramatic look or something more subtle and sophisticated, you're sure to find the perfect product at CrimsonCharm Cosmetics. Discover the magic of this brand, and experience the ultimate in beauty and luxury.</span>\n",
    "\n",
    "**> Finished chain.</br>**\n",
    "'CrimsonCharm Cosmetics is a luxury makeup brand that offers a range of high-quality beauty products, including lipstick, eyeshadow, and foundation. The brand is known for its rich, bold colors and impeccable formulations, which are designed to enhance and beautify any complexion. With a commitment to using only the finest ingredients and state-of-the-art manufacturing techniques, CrimsonCharm Cosmetics has gained a loyal following among beauty enthusiasts and professionals alike. Whether you're looking for a bold, dramatic look or something more subtle and sophisticated, you're sure to find the perfect product at CrimsonCharm Cosmetics. Discover the magic of this brand, and experience the ultimate in beauty and luxury.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ce18c",
   "metadata": {},
   "source": [
    "## SequentialChain\n",
    "- Not all of the sequential chains operate with a single string input and output. In more intricate setups, these chains handle multiple inputs and generate multiple final outputs. \n",
    "- The careful naming of input and output variables holds important significance in these complex chains.\n",
    "- A more general form of sequential chains allows for multiple inputs/outputs. Any step in the chain can take in multiple inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016187ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb0730e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6accf92d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a46121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89603117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b04f45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "review = df.Review[5]\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0b24a7",
   "metadata": {},
   "source": [
    "*Output would look like this:*\n",
    "\n",
    "**> Entering new SequentialChain chain...**\n",
    "\n",
    "\n",
    "**> Entering new LLMChain chain...**</br>\n",
    "Prompt after formatting:</br>\n",
    "<span style=\"color:green\">Human: Translate the following review to english:</span>\n",
    "\n",
    "<span style=\"color:green\">PetalPink lipstick looked lovely in the tube, but the color payoff was disappointing. It took several layers to get the desired hue, and it didn't last long.</span>\n",
    "\n",
    "**> Finished chain.**\n",
    "\n",
    "\n",
    "**> Entering new LLMChain chain...**</br>\n",
    "Prompt after formatting:</br>\n",
    "<span style=\"color:green\">Human: Can you summarize the following review in 1 sentence:</span>\n",
    "\n",
    "<span style=\"color:green\">El lápiz labial PetalPink se veía encantador en el tubo, pero el color no fue satisfactorio. Se necesitaron varias capas para obtener el tono deseado y no duró mucho.</span>\n",
    "\n",
    "<span style=\"color:green\">The PetalPink lipstick looked lovely in the tube, but the color payoff was disappointing. It took several layers to get the desired hue, and it didn't last long.</span>\n",
    "\n",
    "**> Finished chain.**\n",
    "\n",
    "\n",
    "**> Entering new LLMChain chain...**</br>\n",
    "Prompt after formatting:</br>\n",
    "<span style=\"color:green\">Human: What language is the following review:</span>\n",
    "\n",
    "<span style=\"color:green\">PetalPink lipstick looked lovely in the tube, but the color payoff was disappointing. It took several layers to get the desired hue, and it didn't last long.</span>\n",
    "\n",
    "**> Finished chain.**\n",
    "\n",
    "\n",
    "**> Entering new LLMChain chain...**</br>\n",
    "Prompt after formatting:</br>\n",
    "<span style=\"color:green\">Human: Write a follow up response to the following summary in the specified language:</span>\n",
    "\n",
    "<span style=\"color:green\">Summary: The PetalPink lipstick was disappointing due to its poor color payoff and short wear time.</span>\n",
    "\n",
    "<span style=\"color:green\">Language: English</span>\n",
    "\n",
    "**> Finished chain.**\n",
    "\n",
    "**> Finished chain.**</br>\n",
    "\n",
    "{'Review': \"PetalPink lipstick looked lovely in the tube, but the color payoff was disappointing. It took several layers to get the desired hue, and it didn't last long.\",</br>\n",
    " 'English_Review': \"El lápiz labial PetalPink se veía encantador en el tubo, pero el color no fue satisfactorio. Se necesitaron varias capas para obtener el tono deseado y no duró mucho. \\n\\nThe PetalPink lipstick looked lovely in the tube, but the color payoff was disappointing. It took several layers to get the desired hue, and it didn't last long.\",</br>\n",
    " 'summary': 'The PetalPink lipstick was disappointing due to its poor color payoff and short wear time.',</br>\n",
    " 'followup_message': \"Thank you for your feedback on the PetalPink lipstick. We apologize that you were disappointed with the color payoff and wear time of our product. We value our customers' opinions and will take your feedback into consideration as we continue to improve our offerings. Please feel free to reach out to us with any further comments or concerns.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041ea4c",
   "metadata": {},
   "source": [
    "## Router Chain\n",
    "\n",
    "- The Router Chain is used for complicated tasks. If we have multiple subchains, each of which is specialized for a particular type of input, we could have a router chain that decides which subchain to pass the input to.\n",
    "- It consists of:\n",
    "    - **Router Chain:** It is responsible for selecting the next chain to call.\n",
    "    - **Destination Chains:** Chains that the router chain can route to.\n",
    "    - **Default chain:** Used when the router can’t decide which subchain to use.\n",
    "- This involves directing an input toward a specific chain based on what exactly that input is. \n",
    "- When there are several subchains, each tailored for distinct input types, a router chain comes into play. \n",
    "- This router chain acts as a decision-maker, determining which specialized subchain to send the input to. \n",
    "- Essentially, it enables the seamless routing of inputs to the appropriate subchains, ensuring efficient and precise processing based on the input’s specific characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade83f4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f590e9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f50bcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eefec24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f98018a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b2e2ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1387109d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb7d560",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86b2131",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18e0bda",
   "metadata": {},
   "source": [
    "*Output would like this:*\n",
    "\n",
    "**> Entering new MultiPromptChain chain...**</br>\n",
    "physics: {'input': 'What is black body radiation?'}\n",
    "\n",
    "**> Finished chain.**</br>\n",
    "\"Black body radiation refers to the electromagnetic radiation emitted by a perfect black body, which is an object that absorbs all radiation that falls on it and emits radiation at all wavelengths. The radiation emitted by a black body depends only on its temperature and follows a specific distribution known as Planck's law. This type of radiation is important in understanding the behavior of stars, as well as in the development of technologies such as incandescent light bulbs and infrared cameras.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b717379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain.run(\"what is 2 + 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdea117",
   "metadata": {},
   "source": [
    "**> Entering new MultiPromptChain chain...**</br>\n",
    "math: {'input': 'what is 2 + 2'}\n",
    "\n",
    "**> Finished chain.**</br>\n",
    "'As an AI language model, I can answer this question easily. The answer to 2 + 2 is 4.'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
